{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\jmlee\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\jmlee\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\jmlee\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\jmlee\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\jmlee\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\jmlee\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\jmlee\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\jmlee\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\jmlee\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\jmlee\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\jmlee\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\jmlee\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set some parameters\n",
    "IMG_WIDTH = 152\n",
    "IMG_HEIGHT = 60\n",
    "IMG_CHANNELS = 3\n",
    "TRAIN_PATH =r'C:\\Users\\jmlee\\Desktop\\4학년 1학기\\졸프\\U-Net\\input_train'\n",
    "TEST_PATH =r'C:\\Users\\jmlee\\Desktop\\4학년 1학기\\졸프\\U-Net\\input_test'\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n",
    "seed = 42\n",
    "random.seed = seed\n",
    "np.random.seed = seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#한글이름 사진 로드\n",
    "def hangulFilePathImageRead (filePath ) :\n",
    "\n",
    "    stream = open( filePath.encode(\"utf-8\") , \"rb\")\n",
    "    bytes = bytearray(stream.read())\n",
    "    numpyArray = np.asarray(bytes, dtype=np.uint8)\n",
    "\n",
    "    return cv2.imdecode(numpyArray , cv2.IMREAD_COLOR)  #3채널로 가져오기\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for f in os.listdir(TRAIN_PATH):  \n",
    "        if f.split('.')[1] =='jpg':\n",
    "            filePath = (r\"C:/Users/jmlee/Desktop/4학년 1학기/졸프/U-Net/input_train\"+'/'+f)  \n",
    "            train_ids = hangulFilePathImageRead(filePath)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[SEG]전태산_1_1_0_943.jpg'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 23,  23,  23],\n",
       "        [ 25,  25,  25],\n",
       "        [ 28,  28,  28],\n",
       "        ...,\n",
       "        [136, 136, 136],\n",
       "        [125, 125, 125],\n",
       "        [117, 117, 117]],\n",
       "\n",
       "       [[ 23,  23,  23],\n",
       "        [ 24,  24,  24],\n",
       "        [ 24,  24,  24],\n",
       "        ...,\n",
       "        [125, 125, 125],\n",
       "        [124, 124, 124],\n",
       "        [119, 119, 119]],\n",
       "\n",
       "       [[ 21,  21,  21],\n",
       "        [ 21,  21,  21],\n",
       "        [ 20,  20,  20],\n",
       "        ...,\n",
       "        [120, 120, 120],\n",
       "        [118, 118, 118],\n",
       "        [108, 108, 108]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 34,  34,  34],\n",
       "        [ 35,  35,  35],\n",
       "        [ 35,  35,  35],\n",
       "        ...,\n",
       "        [ 53,  53,  53],\n",
       "        [ 42,  42,  42],\n",
       "        [ 38,  38,  38]],\n",
       "\n",
       "       [[ 38,  38,  38],\n",
       "        [ 37,  37,  37],\n",
       "        [ 37,  37,  37],\n",
       "        ...,\n",
       "        [ 53,  53,  53],\n",
       "        [ 44,  44,  44],\n",
       "        [ 40,  40,  40]],\n",
       "\n",
       "       [[ 41,  41,  41],\n",
       "        [ 41,  41,  41],\n",
       "        [ 40,  40,  40],\n",
       "        ...,\n",
       "        [ 53,  53,  53],\n",
       "        [ 43,  43,  43],\n",
       "        [ 38,  38,  38]]], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    for f_ in os.listdir(TEST_PATH):  \n",
    "        if f_.split('.')[1] =='jpg':\n",
    "            filePath = (r\"C:/Users/jmlee/Desktop/4학년 1학기/졸프/U-Net/input_test\"+'/'+f_)  \n",
    "            test_ids = hangulFilePathImageRead(filePath)\n",
    "#             print(f_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'허환이_9_9_0_9730.jpg'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추출된 이미지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.2) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\thresh.cpp:1406: error: (-215:Assertion failed) src.type() == (((0) & ((1 << 3) - 1)) + (((1)-1) << 3)) in function 'cv::threshold'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-07bfd5cf62bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTEST_PATH\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mf_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mret1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mth1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m127\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTHRESH_BINARY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0mret2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mth2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTHRESH_BINARY\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTHRESH_OTSU\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m             \u001b[0mblur\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGaussianBlur\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mret3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mth3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTHRESH_BINARY\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTHRESH_OTSU\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(3.4.2) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\thresh.cpp:1406: error: (-215:Assertion failed) src.type() == (((0) & ((1 << 3) - 1)) + (((1)-1) << 3)) in function 'cv::threshold'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "block_size = 15 # 픽셀에 적용할 threshold값을 계산하기 위한 블럭 크기. 적용될 픽셀이 블럭의 중심이 됨. 따라서 blocksize 는 홀수여야 함\n",
    "subtract_val = 2  #  보정 상수\n",
    "TEST_PATH=r\"C:/Users/jmlee/Desktop/4학년 1학기/졸프/U-Net/정맥추출_전체(152X60)/\"\n",
    "if __name__ == '__main__':\n",
    "    for f_ in os.listdir(TEST_PATH):  \n",
    "        if f_.split('.')[1] =='jpg': \n",
    "            img = imread(TEST_PATH+f_,0)\n",
    "            ret1, th1 = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
    "            ret2, th2 = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "            blur = cv2.GaussianBlur(img,(5,5),0)\n",
    "            ret3, th3 = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "            \n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(img)\n",
    "len(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x163185c1a48>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(th3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting and resizing train images and masks ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/60 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-eaa0a676a43c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mIMG_HEIGHT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIMG_WIDTH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mmask_file\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/masks/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mmask_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/masks/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmask_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Get and resize train images and masks\n",
    "X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "print('Getting and resizing train images and masks ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)): #tqdm:진행바 표시\n",
    "#     path = TRAIN_PATH + id_\n",
    "#     print(path)\n",
    "    path='C:/Users/jmlee/Desktop/4학년 1학기/졸프/U-Net/input_train/'\n",
    "    img = imread(path+f)[:,:,:IMG_CHANNELS]\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_train[n] = img\n",
    "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "    for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
    "        mask_ = imread(path + '/masks/' + mask_file)\n",
    "        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n",
    "                                      preserve_range=True), axis=-1)\n",
    "        mask = np.maximum(mask, mask_)\n",
    "    Y_train[n] = mask\n",
    "\n",
    "# Get and resize test images\n",
    "X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "sizes_test = []\n",
    "print('Getting and resizing test images ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
    "    path='C:/Users/jmlee/Desktop/4학년 1학기/졸프/U-Net/input_test/'\n",
    "    img = imread(path+f_)[:,:,:IMG_CHANNELS]\n",
    "    sizes_test.append([img.shape[0], img.shape[1]])\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_test[n] = img\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
